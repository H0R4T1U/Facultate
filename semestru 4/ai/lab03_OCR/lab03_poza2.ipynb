{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting jellyfish\n",
      "  Downloading jellyfish-1.1.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Downloading jellyfish-1.1.3-cp39-cp39-macosx_11_0_arm64.whl (311 kB)\n",
      "Installing collected packages: jellyfish\n",
      "Successfully installed jellyfish-1.1.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from jiwer import wer, cer\n",
    "from array import array\n",
    "from Levenshtein import distance as levenshtein_distance, hamming\n",
    "from dotenv import dotenv_values\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEND - Authenticate\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "config = dotenv_values(\".env\")\n",
    "subscription_key = config[\"VISION_KEY\"]\n",
    "endpoint = config[\"VISION_ENDPOINT\"]\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "'''\n",
    "END - Authenticate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"test2.jpeg\"\n",
    "image = cv2.imread(image_path)\n",
    "image_gray = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "image_thresh = thresholding(image_gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ocr_tesseract(image):\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "def ocr_azure(image_path):\n",
    "\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        read_response = computervision_client.read_in_stream(\n",
    "        image=image_file,\n",
    "        mode=\"Printed\",\n",
    "        raw=True\n",
    "        )\n",
    "\n",
    "        operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "        while True:\n",
    "            read_result = computervision_client.get_read_result(operation_id)\n",
    "            if read_result.status not in ['notStarted', 'running']:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        result = []\n",
    "        if read_result.status == OperationStatusCodes.succeeded:\n",
    "            for text_result in read_result.analyze_result.read_results:\n",
    "                for line in text_result.lines:\n",
    "                    print(line.text)\n",
    "                    result.append(line.text)\n",
    "    \n",
    "    return \" \".join([line for line in result])\n",
    "\n",
    "def evaluate_recognition(ground_truth, recognized_text):\n",
    "    lev_dist = levenshtein_distance(ground_truth, recognized_text)\n",
    "    word_err = wer(ground_truth, recognized_text)\n",
    "    char_err = cer(ground_truth, recognized_text)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"Levenshtein Distance\": lev_dist,\n",
    "        \"Word Error Rate\": word_err,\n",
    "        \"Character Error Rate\": char_err\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract OCR Result:\n",
      " PEMELOR Sa.\n",
      "\n",
      "LAOORA toarele  ohe\n",
      "\n",
      "\n",
      "Lucces in resolvarea\n",
      "TEMELOR la\n",
      "LABORA toarele de\n",
      "Inteligenta Artificialà!\n",
      "Azure OCR Result:\n",
      " Lucces in resolvarea TEMELOR la LABORA toarele de Inteligenta Artificialà!\n",
      "Tesseract Evaluation: {'Levenshtein Distance': 34, 'Word Error Rate': 1.0, 'Character Error Rate': 0.8194444444444444}\n",
      "Azure Evaluation: {'Levenshtein Distance': 74, 'Word Error Rate': 0.7777777777777778, 'Character Error Rate': 0.2777777777777778}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "ground_truth_text = [\"Succes in rezolvarea temelor la laboratoarele de inteligenta artificiala\"]\n",
    "\n",
    "# OCR using Tesseract\n",
    "tesseract_result = ocr_tesseract(image_thresh)\n",
    "print(\"Tesseract OCR Result:\\n\", tesseract_result)\n",
    "\n",
    "# OCR using Azure (replace with your credentials)\n",
    "azure_result = ocr_azure(image_path)\n",
    "print(\"Azure OCR Result:\\n\", azure_result)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Tesseract Evaluation:\", evaluate_recognition(ground_truth_text, tesseract_result))\n",
    "print(\"Azure Evaluation:\", evaluate_recognition(ground_truth_text, azure_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 15:17:29.048 Python[23680:4222234] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-18 15:17:29.048 Python[23680:4222234] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "h, w,c = image.shape\n",
    "boxes = pytesseract.image_to_boxes(image_thresh)\n",
    "\n",
    "# Draw rectangles around detected text\n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    x1, y1, x2, y2 = int(b[1]), int(b[2]), int(b[3]), int(b[4])\n",
    "\n",
    "    # Fix y-coordinates by subtracting from image height\n",
    "    y1, y2 = h - y1, h - y2\n",
    "\n",
    "    # Draw the bounding box\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('img', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Succes in rezolvarea', 'xmin': 74, 'ymin': 291, 'xmax': 1340, 'ymax': 465}, {'name': 'temelor la', 'xmin': 127, 'ymin': 573, 'xmax': 1049, 'ymax': 731}, {'name': 'laboratoarele de', 'xmin': 73, 'ymin': 920, 'xmax': 1004, 'ymax': 1036}, {'name': 'inteligenta artificiala', 'xmin': 88, 'ymin': 1120, 'xmax': 1459, 'ymax': 1377}]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load and parse the XML file\n",
    "xml_file = \"boxes2.xml\" \n",
    "tree = ET.parse(xml_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract bounding boxes\n",
    "ground_truth_boxes = []\n",
    "for obj in root.findall(\"object\"):\n",
    "    name = obj.find(\"name\").text\n",
    "    bndbox = obj.find(\"bndbox\")\n",
    "    \n",
    "    bbox = {\n",
    "        \"name\": name,\n",
    "        \"xmin\": int(bndbox.find(\"xmin\").text),\n",
    "        \"ymin\": int(bndbox.find(\"ymin\").text),\n",
    "        \"xmax\": int(bndbox.find(\"xmax\").text),\n",
    "        \"ymax\": int(bndbox.find(\"ymax\").text),\n",
    "    }\n",
    "    \n",
    "    ground_truth_boxes.append(bbox)\n",
    "\n",
    "print(ground_truth_boxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\t# compute the intersection over union by taking the intersection\n",
    "\t# area and dividing it by the sum of prediction + ground-truth\n",
    "\t# areas - the intersection area\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\t# return the intersection over union value\n",
    "\treturn iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform OCR\n",
    "with open(image_path, 'rb') as image_file:\n",
    "        ocr_result = computervision_client.read_in_stream(\n",
    "        image=image_file,mode=\"Printed\",raw=True)\n",
    "\n",
    "        operation_location = ocr_result.headers[\"Operation-Location\"]\n",
    "        operation_id = operation_location.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "        while True:\n",
    "            result = computervision_client.get_read_result(operation_id)\n",
    "            ground_truth_box = [];\n",
    "            if result.status not in ['notStarted', 'running']:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        result_box = []\n",
    "        if result.status == OperationStatusCodes.succeeded:\n",
    "            read_results = result.analyze_result.read_results\n",
    "            h, w, c = image.shape\n",
    "            i=0;\n",
    "            for read_result in read_results:\n",
    "                for line in read_result.lines:\n",
    "                    for word in line.words:\n",
    "                        bbox = word.bounding_box\n",
    "                        result_box.append(bbox)\n",
    "                        x1, y1 = int(bbox[0]), int(bbox[1])\n",
    "                        x2, y2 = int(bbox[4]), int(bbox[5])\n",
    "                        image = cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        for box in ground_truth_boxes:\n",
    "            cv2.rectangle(image, (box[\"xmin\"], box[\"ymin\"]), (box[\"xmax\"], box[\"ymax\"]), (0, 0, 255), 2)  # Blue for GT\n",
    "        for i in range(len(ground_truth_box)):\n",
    "            bbox=result_box[i]\n",
    "            box = ground_truth_boxes[i]\n",
    "            coordonate_result = [bbox[0],bbox[1],bbox[4],bbox[5]]\n",
    "            coordonate_ground = [box[\"xmin\"], box[\"ymin\"],box[\"xmax\"],box[\"ymax\"]]\n",
    "            iou = bb_intersection_over_union(coordonate_result,coordonate_ground)\n",
    "            print(f\"IOU of{box['name']} is {iou}\")\n",
    "        # Display the image\n",
    "        cv2.imshow('img', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
